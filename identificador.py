# -*- coding: utf-8 -*-
"""ProjetoSinais.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NAXxiE9OxLLd__FhasRV28V1tUtUjRBf

#### Importando nosso dataset com 40 imagens contendo placas sinalizadoras de velocidade de trânsito
"""

! mkdir dataset
! unzip dataset.zip -d dataset

"""#### Instalando dependências e importando bibliotecas para implementação da solução

#####  

*   cv2 para permitir tratamento das imagens
*   glob para instancias o dataset
*   imultils para especialmente resizing e contornos
*   easyocr para identificação de caracteres na imagem   


"""

!pip install easyocr
!pip install texttable
import numpy as np
from google.colab.patches import cv2_imshow
import cv2
import glob
import imutils
import easyocr
from prettytable import PrettyTable
from keras.preprocessing import image
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.model_selection import GridSearchCV, train_test_split
from skimage.io import imread
import skimage.filters
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', 30*30 + 1)

"""#### Implementação do filtro utilizando os métodos relacionados à Transformada Rápida de Fourier da biblioteca numpy"""

def filtroFFT(img, size = 10):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    
    #aplicando um filtro de passa alta
    linhas, colunas = img.shape
    crow,ccol = linhas//2 , colunas//2
    fshift[crow-size:crow+(size+1), ccol-size:ccol+(size+1)] = 0

    # espectro de magnitude da imagem em processamento antes e após o high pass filter
    f_and_fshift = np.concatenate((f, fshift), axis=1)
    print("espectro de magnitude da imagem em processamento antes (esquerda) e após o high pass filter (direita)")
    cv2_imshow(f_and_fshift)
    print("\n\n")

    #aplicação da transformada inversa para pegar o retorno da imagem
    f_ishift = np.fft.ifftshift(fshift)
    img_inverted = np.fft.ifft2(f_ishift)
    img_inverted = np.real(img_inverted)

    return img_inverted

"""#### Filtro anti glimmering para pré-processamento"""

def filtroAntiGlimmering(img):
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            if(img[i][j] > 128):
                img[i][j] = max(128, img[i][j]*0.85)
            else:
                img[i][j] = min(128, img[i][j]*1.15)
    return img

"""#### Definição do filtro estatístico de edge-sharp para finalizar o pré-processamento, deixando as bordas da imagem mais nítidas"""

def edgeSharpFilter(img):
    ker = np.array([
                [-1, -1, -1],
                [-1, 18, -1],
                [-1, -1, -1]])
    ker = (1.0/10.0) * ker
    flipped = cv2.flip(ker, 0)
    img = cv2.filter2D(img,-1,flipped, delta=0, anchor=(2,2))
    return img

"""#### Após ter a imagem via transformada inversa, normalizamos para garantirmos que todos os pixels da imagem estejam entre 0 e 255, permitindo detecção dos contornos"""

def normalizador(img):
    normalized = np.zeros(img.shape)
    normalized = cv2.normalize(img,  normalized, 0, 255, cv2.NORM_MINMAX)
    (thresh, blackAndWhiteImage) = cv2.threshold(normalized, 127, 255, cv2.THRESH_BINARY_INV)
    img = blackAndWhiteImage

    # os pixels com valores negativos são agora zerados
    img = img.astype(np.uint8)
    
    return img

"""#### Dada a imagem em questão e os frames detectados após o get dos contornos baseado na imagem invertida, identificamos aqueles que contêm textos (utilizando a biblioteca easyocr)"""

def identificarPlacas(imgRef, frames):
    reader = easyocr.Reader(['en']) # inicializando leitor de textos em inglês
    retangulosTextuais = []
    for f in frames:
        x,y,width,height = f[1]

        # pegando os pixels da imagem dentro de cada frame
        recorte = imgRef[y:y+height, x:x+width] 

        # tentando ler algum texto dentro desse recorte
        ans = reader.readtext(recorte)

        for element in ans:
            (_, text, _) = element
            contains_digit = any(map(str.isdigit, text))
            # se houver texto numérico no recorte, adicionar o frame à lista
            if contains_digit and len(text) > 1:
                retangulosTextuais.append(f[1])
    
    return retangulosTextuais

"""#### Método para detectar os contornos da imagem obtida via transformada inversa"""

def getContours(img, img_back, imgRef):
    contornos = cv2.findContours(img_back.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    contornos = imutils.grab_contours(contornos)
    contornos = sorted(contornos,key=cv2.contourArea, reverse = True)[:30]
    usefulRects = None
    selectedsFrames = []
    sinalizacao = 0
    
    for c in contornos:
        # pegando os parâmetros que definem o retângulo identificado no contorno e adicionando à lista
        x,y,width,height = cv2.boundingRect(c)
        ratio = width/height

        # são adicionados aqueles retângulos com dimensões mais prováveis de envolver uma placa de trânsito
        if ratio > 0.75 and ratio < 1.33:
          selectedsFrames.append([width*height,[x,y,width,height]])

    selectedsFrames = sorted(selectedsFrames, key=lambda x: x[0])
    usefulRects = identificarPlacas(imgRef, selectedsFrames)

    if len(usefulRects) == 0:
        print ("Nenhuma placa sinalizadora de velocidade identificada")
        
    else:
        sinalizacao = 1
        for r in usefulRects:
            x,y,width,height = r

            # desenha os retângulos azuis que, segundo o easyocr, contêm textos númericos em seu interior (via img_back)
            cv2.rectangle(imgRef, (x,y), (x+width, y+height), (255, 0, 0), 2)

    return imgRef, img_back, sinalizacao

"""#### Listando as 40 imagens redimensionadas do dataset utilizando a biblioteca glob"""

#exploring the dataset
list_images = list(glob.iglob("dataset/*"))

for image in list_images:
  img = cv2.imread(image, cv2.IMREAD_COLOR)
  img = imutils.resize(img, width=512)
  cv2_imshow(img)

"""#### Implementação final da nossa solução ao problema definido"""

placasDetectadasPorImagem = []

for image in list_images:
  img = cv2.imread(image, cv2.IMREAD_COLOR)
  img = imutils.resize(img, width=512, height=512)

  imgBase = img.copy()
  originalImg = img.copy()

  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  img = filtroAntiGlimmering(img)
  img = edgeSharpFilter(img) # img agora está pré-processada

  # imprimindo imagem original e pré-processada
  print("imagem original")
  cv2_imshow(originalImg)
  print("\n\n")

  print("imagem pré-processada")
  cv2_imshow(img)
  print("\n\n")

  # aplicando a transformada rápida e inversa
  img_back = filtroFFT(img)

  # normalizando a imagem inversa
  img_back = normalizador(img_back)

  # detectando os contornos e definindo os retângulos identificadores das placas sinalizadoras
  img, img_back, detected = getContours(img, img_back, imgBase)
  img_back = cv2.cvtColor(img_back,cv2.COLOR_GRAY2RGB)
        
  img_and_magnitude = np.concatenate((imgBase, img_back), axis=1)
  
  # imagem original com os retângulos identificados a partir da imagem processada
  print("imagem com possíveis identificadores de placas (esquerda) e imagem da magnitude espectral (direita)")
  cv2_imshow(img_and_magnitude)

  # adicionando as imagens associadas ao resultado da identificação
  placasDetectadasPorImagem.append([image, detected])

  print("===========================================================================================================================================\n\n")

"""#### Tabela de resultados, para cada imagem há a indicação se houve ou não identificação das placas"""

t = PrettyTable(['Images', 'Detected?'])
print(len(placasDetectadasPorImagem))

for i in range(len(placasDetectadasPorImagem)):
  t.add_row([placasDetectadasPorImagem[i][0], bool(placasDetectadasPorImagem[i][1])])

print(t)